{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the OpenAI API\n",
    "\n",
    "First, install the openai module if it is not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment\n",
    "\n",
    "In this notebook, we will be getting the OpenAI API key from the environment. Make sure the directory contains a `.env` file with your key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\", override=True) \n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a first prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\"gpt-3.5-turbo-1106\", \"gpt-4\", \"gpt-4o\", \"gpt-3.5-turbo-16k\"]\n",
    "MODEL = MODELS[0]\n",
    "client = OpenAI()\n",
    "\n",
    "def query_openai(client, prompt, model):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "            messages=[{\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be asked to help with programming questions.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }],\n",
    "        max_tokens=256\n",
    "        )\n",
    "    return(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "prompt_text = \"Provide some Perl code to write `Hello world` in five different ways.\"\n",
    "response_text = query_openai(client, prompt_text, MODEL)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data from an API\n",
    "\n",
    "In this example we will get data from a public API and ask ChatGPT to reason about this.\n",
    "First, we need the code to access the API. In our case we are looking at Gene Ontology database, but you can use another API as well of course.\n",
    "You can do this through the ChatGPT web interface, but for now we will stick to the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_text = \"I need to query the gene ontology database through the API. Can you provide code which gives information on GO:0030445?\"\n",
    "response_text = query_openai(client, prompt_text, MODEL)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accessing the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Make a GET request to the gene ontology API\n",
    "response = requests.get('http://www.ebi.ac.uk/QuickGO/services/ontology/go/terms/GO:0030445')\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Convert the response to JSON\n",
    "    data = response.json()\n",
    "    \n",
    "    # Print the information for GO:0030445\n",
    "    print(\"GO Term ID:\", data['results'][0]['id'])\n",
    "    print(\"GO Term Name:\", data['results'][0]['name'])\n",
    "    print(\"GO Term Definition:\", data['results'][0]['definition']['text'])\n",
    "else:\n",
    "    print(\"Failed to get information for GO:0030445\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a function to get all information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_go(GOterm):\n",
    "    # Make a GET request to the gene ontology API\n",
    "    response = requests.get(\"http://www.ebi.ac.uk/QuickGO/services/ontology/go/terms/{}\".format(GOterm))\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Convert the response to JSON\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        print(\"Failed to get information for {}\".format(GOterm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have ChatGPT make a summary of the data. First we need a more general function to query the OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_openai(client, system, prompt, model):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "            messages=[{\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }],\n",
    "        max_tokens=256\n",
    "        )\n",
    "    return(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_go_term = \"GO:0030445\"\n",
    "system_prompt = \"You are a skilled biologist and a good lecturer.\"\n",
    "\n",
    "go_json = get_go(my_go_term)\n",
    "summary = query_openai(client=client, \n",
    "                       system=system_prompt, \n",
    "                       prompt=\"I have this json from the Gene Ontology database. Could you create a nice summary of the biological data? There is no need to comment on the structure of the JSON: `{}`\".format(go_json), \n",
    "                       model=MODEL)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = query_openai(client=client,\n",
    "                      system=system_prompt,\n",
    "                      prompt=\"Given the summary of this GO term, could you provide a markdown report on this GO term with more background information? Please only markdown, no other comments or explainations. `{}`\".format(summary),\n",
    "                      model=MODEL)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
